# Análisis de Variantes Detectadas por Secuenciación Masiva

Comentarios acerca de cómo analizar variantes detectadas por secuenciación masiva de ADN.





LINEAMIENTO PARA EL ANÁLISIS DE VARIANTES DE SECUENCIACIÓN MASIVA

1. Correr las muestras por Variant Effec Predictor (VEP) eligiendo todas las opciones que te ofrece este programa en línea, para el GRCh37, a menos que se diga lo contrario o que se actualice en ese sentido los software de la unidad de secuenciación.
2. Una vez teniendo el resultado del procesamiento de VEP, tienes que bajar los resultados o leerlos directamente como sea sencillo, lo ideal es bajar en .txt  el resultado de todas las variantes y además uno por cada filtro, es decir un programa que sólo incluya sift, otro que sólo incluya los resultados de polyphen, otro que incluya clinsig, y asi sucesicamente, este punto lo desgloso en el número 3.
3. Yo en lo personal prefiero hacer manualmente la filtración, primero se hará por los programas ya conocidos y probados, es decir en una página de Excel pondrás en un mismo libro todas las variantes, para que tengas un referente y sobre todo por si luego tienes que ir a buscar una en específico, a esa no  le harás nada, sólo la dejarás allí. Luego copiarás todas esas variantes y las pegarás en una carpetita nueva, donde filtrarás rápidamente las que corresponden a clinsig, solo las que están reportadas como desconocidas, probablemente patológicas o patológicas son las que te quedarás, el resto las desechas.
4. En otra carpetita vuelves a hacer lo mismo pero ahora filtras sólo las que dicen algo en sift, como no conocidas o deletéreas, desechando aquellas que se reporten como toleradas o no digan nada, también aquí ya desechas las que dicen algo en clinsig para que no leas dos veces la misma información.
5. En una tercera carpetita ahora filtras las que dicen algo en polyphen, desechando todas las que dicen algo en sift o clinsig o no dicen nada en polyphen.
6. En una cuarta carpeta ahora filtras las que dicen algo en polyphen y que en sift se reportan como toleradas, este paso ocurre porque en los anteriores desechaste estas variantes y no deben quedar variantes sin darles un vistazo, y aunque este paso se puede hacer en la anterior, yo prefiero dividirlo para que no me tarde mucho.
7. En otra carpeta colocas sólo las que dicen en el segmento de consecuencia stop o star lost, el resto las desechas, y de estas desechas también las que digan algo en polyphen, sift o clinsig, porque todas esas ya las viste.
8. En otra carpeta pones las que dicen algo en CADD_phred, eliminando el resto y también las que antes ya viste, es decir, las que tienen algo en polyphen, sift, consecuencia o clinsig, esto de la eliminación es algo que vas a hacer con cada una de las que vienen, de tal forma que tienes que ir filtrando sin perder información y sin que algún dato se quede también sin ser leído. Una nota importante y útil es que en las que vienen elegirás todas las variantes en que haya algún reporte o puntuación, después irás eliminando individualmente de acuerdo con algunos datos que te daré más adelante, aquí para que no te pierdas, si dice alguna letra o número, los eliges todos, sin excepción, sólo eliminando como te dije, aquellas que ya habías leído.
9. De esa forma vas a ir haciendo una carpeta para Ancestral_allele, CADD_phred, FATHMM_pred, GERP++_RS, LRT_pred, MetaLR_pred, MetaSVM_pred, MutationAssessor_pred, MutationTaster_pred, PROVEAN_pred, Reliability_index, todos los clinvar, VEST, BLOSUM62 y Condel, como vez, son ya demasiados y todos aportan datos importantes e interesantes, por lo que debes considerarlos, utilizar sólo Sift y Polyphen como únicos predictores estadísticamente hablando es incorrecto.
10. Una vez que tienes todas tus carpetas vas a marcar o eliminar (yo prefiero marcar con un color que sé que no voy a utilizar sólo en caso de ser necesario) aquellas donde se observa en la columna de locación un fenómeno de continuidad, por ejemplo 1:7340196, 1:7340197, 1:7340203, etc. porque estas reflejan más que nada un error de la polimerasa al momento de la secuenciación que de un dato real, de esa forma ya te quedas con menos variantes para trabajar por cada carpeta.
11. El siguiente paso es abrir algún programa como Tablet, BWA o IGV (este último es el que tenemos más probado y con mayor experiencia) para visualizar tus variantes, que serán todas aquellas que se encuentren sin marcar hasta este momento en cada una de tus carpetas de sift, polyphen, clinsig, consecuencia, sift y polyphen, para las otras carpetas de programas nuevos es lo mismo pero te diré más adelante los parámetros para que además de este les hagas un filtro adicional.
12. Los criterios para IGV ya están en otro escrito que también te hice llegar vía correo electrónico y que anexo nuevamente en otro documento. Las que no pasan la prueba con criterios de IGV yo prefiero marcarlas de un color oscuro, en señal de que ya las vi y no pasan los criterios mínimos necesarios de IGV, y por tanto no podrían pasar a la siguiente fase.
13.  Las que pasan los criterios de IGV pero con ciertas dudas las marco en amarillo, haciendo referencia al semáforo, como dejándolas en señal de alarma y que en un momento dado podrían utilizarse dependiendo lo que encontremos en otras.
14. Las que pasan a la perfección los criterios de IGV, como para asegurar que incluso se verán sin necesidad de ser confirmadas, las marco de rojo, en señal de que son potenciales candidatas a hacer un siguiente análisis.
15. El análisis siguiente es con las bases de datos NCBI. En esta función buscaremos aquellas en todas las carpetas, ordenándolas lógicamente para facilitar ese proceso, aquellas que ya se conocen y por tanto tienen un rs, aquí la dinámica es que primero me voy a la primera columna del Excel (#Uploaded_variation) y en la columna de Existing_variation, allí es donde se ubican todos los rs. Ya en el NCBI, primero busco en SNP y coloco el rs, si desde allí me dice que es benigna por ejemplo, o que el significado clínico es no conocido y que además es intrónica, desde allí la desechamos, no perdemos el tiempo y pasamos a otra variante. Desglosaré este punto:
16. Si la variante se reporta como probable patológica o patológica entonces la revisamos en ClinVar, incluso también revisamos las que dicen no conocida o desconocida, siempre y cuando no sea intrónica. Si es intrónica pero se reporta como patológica o probable patológica, las seleccionamos invariablemente para seguir estudiándola. 
17. Ya en clinvar debemos revisar si el cambio de aminoácido y el cambio de nucleótido que tiene nuestro paciente coincide con el que reportan en la literatura, para esto nos podemos apoyar en el Excel (obtenido de la salida del VEP), en las columnas de Allele, HGVSc, HGVSp, cDNA_position, CDS_position, Protein_position, Amino_acids, Codons y MutationTaster_AAE. Si no hay coincidencia, la única manera por la que la que podríamos aceptarla es que no sea intrónica y que además en otros programas de predicción se reporte como patológica o probable patológica y que además tenga una buena calidad al IGV.
18. Si ya paso la prueba de ClinVar como probable candidata, debemos ahora revisarla en 1000 genomas y aquí, en teoría, si tiene una frecuencia de 1 % o mayor  en la población mexicana y en las otras poblaciones, debería desecharse, no obstante si se ha encontrado y hay artículos donde dice que si es patológica, la dejaremos sin importar mucho la frecuencia, esto para una discusión posterior, en este proceso no quedan muchas, quizá unas dos o tres por cada 20 pacientes. Con esto quiero decir que debes introducirte al OMIM y al PubMed, incluso hacer Blast si es requerido para ver si se acepta o no. Una nota adicional en este punto, es que debes poner atención en que si en clinvar resulta como desconocida, pero en otros programas es patológica, entonces la aceptamos, el sólo hecho de que clinvar la tengan como desconocida no es un criterio de selección, ahora tienes muchísimos más programas para discernir en esta selección, estos programas ya los mencione arriba. Lo que hasta aquí te describí es para las variantes conocidas y que además tienen una buena calidad en IGV.
19. Lo anterior descrito es para cada una de las carpetas que se describieron, exceptuando clinsig y clinvar, todos los demás son programas de predicción, por tanto en todos los demás sólo podremos aceptar exones, desecharemos todas aquellas que sean intrónicas, para esto podríamos basarnos en las columnas llamadas INTRON, EXON y Feature_type de la salida del VEP, pero estas no siempre coinciden con lo real, ya que su actualización es más lenta que la que ocurre en la base de datos del NCBI, puedes basarte mejor en el IGV que es un visualizador en tiempo real con las bases de datos y también en el NCBI mismo, dejando claro que si encuentras variantes intrónicas probable patológicas, no reportadas en clinsig ni polyphen, las debes desechar, a menos que se trate de un programa predictivo que calcula el efecto del Splicing, que ya comentaré más adelante.
20. Ahora sí, ya especificando los datos anteriores, vamos a ver cada uno de los programas que te redacte desde el punto 8 y 9, los filtros que debes aplicar en estos en particular, además de los ya comentados (variantes continuas, intrónicas no reportadas en ClinVar y sin reporte en ningún predictor) y los parámetros que considerarás para analizarlos en el IGV o en su defecto en el NCBI si son conocidos; recuerda que entre más programas reporten una variante como patológica, la probabilidad de que esta lo sea es mucho mayor; también puede ocurrir lo contrario, si sólo uno o dos la reportan como patológica, la probabilidad de que lo sea será menor; al final de todo el análisis completo se espera queden más variantes que en la forma del análisis anterior, pero también se espera que queden con mayor valor predictivo para ser verificadas por Sanger, de aquí esperamos que la variante causal prácticamente sea evidente. Una nota adicional es que los lineamientos de este tipo de análisis están en constante cambio dependiendo de las actualizaciones y de la experiencia adquirida, de tal manera que no te sorprenda que en breve te presente algunas mejoras al mismo. Por último cabe mencionar que tú vas a aceptar cualquier variante para por lo menos revisarla en IGV y hacerle análisis posteriores en NCBI si lo requiere, si al menos se reporta como patológica en uno de todos los predictores o bases de datos.
21. Consequence: en esta columna se reportan el efecto que el cambio de nucleótido tuvo en al transcrito, y aquí sólo vamos a aceptar las que produjeron un codón de paro (stop) y a star lost, el resto aunque es importante es difícil de evaluar por este análisis, para ello existen todos los predictores.
22. SIFT: ya conocido, contempla los siguientes parámetros: D: Deleterious (sift<=0.05); T: tolerated (sift>0.05), aquí nosotros sólo aceptaremos las que se reporten como Deleterius, o tolerated pero que contemplen otros predictores, no por si solas.
23. PolyPhen: igual que el anterior es ya conocido, contempla los siguientes parámetros: D: Probably damaging (>=0.957), P: possibly damaging (0.453<=pp2_hdiv<=0.956); B: benign (pp2_hdiv<=0.452), aquí descartaremos a la siguiente fase aquellas que se reporten como benignas o que no tengan ningún reporte.
24. CLIN_SIG: lo mismo que en ClinVar, se basan en el significado clínico observado en estudios previos, aquí se contemplaran para una segunda etapa de análisis aquellas que se reporten como probablemente patológicas, patológicas, benigna-probablemente patogénica, benigna-patogénica, no provisto e incierto, descartando a todas las demás.
25. Ancestral_allele: esta columna es importante sólo para las variantes que sean de interés, es decir aquellas en las cuales se diga algo que es probable patológico en algún predictor o base de datos (Clin_Sig, ClinVar), y para sacarle el máximo provecho debes pensar con tus conocimientos de genética de poblaciones y con lo de genómica que has aprendido y al mismo tiempo como clínico. Se complementa con columnas como AFR_MAF, AMR_MAF, EAS_MAF, etc., que tienes del Excel dado por el VEP, pero en lo personal si lo requieres yo preferiría revisarlo directamente en la página de 1000 genomas. Para ponerte un ejemplo, si el cambio de base es una A>T, y revisas y resulta que la T es la más frecuente en todas las poblaciones y la A prácticamente es nula, entonces estarías ante una probable mutación, porque el ancestral (que es T) se ha conservado. Otro ejemplo, con el mismo cambio (A>T), si el ancestral se ha perdido entre las poblaciones, siendo frecuente en Africa, menos frecuente en Europa, luego menos frecuente en Asia y luego ya muy poco frecuente en America, es probable que el patológico dependiendo del ambiente y otras condiciones, pudiera ser el alelo ancestral, es decir el T y el A en realidad le produzca hasta una ventaja. Y Así se debe analizar individualmente cada caso sólo que sea necesario hacerlo, para esta columna en particular de Ancestral_allele, aunque lo insinué antes, no requieres una carpeta aparte, sino más bien poner atención en las variantes que por cumplir criterios han sido seleccionadas como probables candidatas, entonces aquí vendría siendo este análisis un filtro adicional para elegir o no elegir una variante.
26. Combined Annotation Dependent Depletion (CADD_phred y CADD_Raw): en pocas palabras este programa es un predictor funcional de los SNP, si el puntaje es alto es más probable que el SNP sea patológico, el puntaje del mismo surge dependiendo del alelo alterado. Las diferentes formas del CADD que hay en la literatura depende de las diferencias en la estadística del puntaje que cada uno arroja, pero en conclusión son semejantes, esto pasa con varios programas. CADD RAW va de 0 a 1 y CADD Phred de 10 a 20, en ambos parámetros estarían las patológicas, aquellas que tengan un puntaje mayor a 1 o mayor a 20. Tú tienes en el Excel que salió del VEP a las dos, por raw elige las que sean mayor a 0, descartando las menores o igual a 0 ó negativas, en phred elije las que sean mayor a 10, eliminando las menores, esto porque entre 0 y 1, o entre 10 y 20 están además las probablemente patológicas y las que son mayores a 1 y mayores a 20 están las patológicas. En este punto como en los demás tú ya aplicaste otros filtros ya comentados y las variantes con las que trabajarás son mucho menos que al inicio.
27. Functional Analysis through Hidden Markov Models (FATHMM_pred): Este programa trabaja prácticamente de la misma forma que Sift y Polyphen, no obstante se comenta que es más preciso que ambos, dando datos más exactos y apegados a la realidad. La puntuación para estas se basa en datos estadísticos pero concluye fácilmente en D: Deleterious; T: Tolerated, elegirás sólo las que tengan D desechando el resto. Para este como para otros vamos a considerar sólo esta columna porque da el resultado más rápido y fácil que las otras columnas derivadas de este, que dan los datos matemáticos, que si bien son lo mismo expresado matemáticamente, quitan más tiempo, lo mismo se repetirá en las siguientes columnas.
28. Genomic Evolutionary Rate Profiling (GERP++_RS):  Este programa calcula la conservación en términos de evolución de una variante y sus efectos positivos y negativos cuando hay cambios; es uno de los más complejos de entender, pero te lo voy a resumir de la siguiente manera: Una puntuación GERP positiva indica que un sitio puede estar bajo selección purificadora o sujetos a una tasa de mutación por debajo del promedio, mientras que una puntuación negativa puede indicar más débil selección purificadora o una tasa de mutación por encima del promedio. Por tanto entre mayor sea el puntaje, se mantiene más conservado, lo cual puede ser positivo o negativo de acuerdo a que estemos hablando. Para fines de este proyecto elegirás todas aquellas variantes que te den puntuaciones negativas, que significa que en ellas habrá más probablemente mutaciones, esto claro con los otros criterios antes comentados.
29. LRT_pred: El método LRT utiliza el cociente de probabilidad log de la variante conservada en relación con un modelo neutral para medir la alteración de un SNP. El puntaje establecido y fácil de entender es D: Deleterious; N: Neutral; U: Unknown, de entre las cuales elegirás sólo las que te dicen D o Deleterius, desechando el resto.
30. MetaLR_pred y MetaSVM_pred: Estos dos programas son muy semejantes, por lo que te recomiendo los pongas juntos en una misma carpetita, y tu criterio de selección sea según la conclusión a la que llego el puntaje en D: Deleterious; T: Tolerated, aceptando solamente las D, desechando las variantes que digan T, y que basta con que un programa diga D para que sea aceptado para pasar al siguiente análisis, aunque el otro diga T. Ambos programas fueron desarrollados por Coco Dong, estos programas normalizan los puntajes y presentan la información de una manera más fácil de entender, los han comparado con otros como PolyPhen-2, SIFT, MutationTaster, Mutation Assessor, FATHMM, LRT, PANTHER, PhD-SNP, SNAP, SNPs&GO, y MutPred,  asi como los programas de conservación como GERP++, SiPhy y PhyloP  y otros que miden la calidad de síntesis como CADD, PON-P, KGGSeq y CONDEL, mostrando gran efectividad y facilidad en el resultado final, por tanto son una buena opción.
31. MutationAssessor_pred: Este programa predice el impacto funcional de la sustitución del aminoácido en la proteína sea producido por una mutación o un polimorfismo. El impacto funcional es evaluado basándose en la conservación evolutiva que afecta al aminoácido en la proteína homologa. A lo que llevan los cálculos y los puntajes de este programa se resumen en la siguiente clasificación: H: high; M: medium; L: low; N: neutral. H/M means functional and L/N means non-functional. Más de 3.5 se clasifican como alto impacto (deletéreo) y de estas por tanto nosotros vamos a elegir aquellas que tienen H, M y H/M, desechando el resto. 
32. MutationTaster_pred: Este es una aplicación libre en la red para llevar a cabo una rápida evaluación del cambio de la secuencia del DNA potencialmente causante de la enfermedad en cuestión. Integra información de diferentes bases de datos biomédicos y los integra, termina analizando eventos de conservación, cambios en el sitio de Splice, pérdida de las características de la proteína y otros cambios que pudieran afectar la cantidad de RNAm. En resumen los resultados los concreta de la siguiente manera: A" ("disease_causing_automatic"); "D" ("disease_causing"); "N" ("polymorphism"); "P" ("polymorphism_automatic". Nosotros sólo aceptaremos las letras A y D. Desechando el resto. Vas a encontrar una columna muy práctica, que dice MutationTaster_AAE, te resumen los cambios de aminoácidos y en qué posición, esa información puede serte útil en la investigación documental del NCBI. 
33. Protein Variation Effect Analyzer (PROVEAN_pred): en otros momentos encontré que este programa no aporta datos útiles y que consumía mucho tiempo en su utilización directamente en la web, no obstante ahora lo aporta el VEP y de una manera sencilla que no quita más tiempo que el resto se puede utilizar como complemente a los otros predictores. Se dice de este programa que predice si una sustitución de un aminoácido o indel tiene un impacto biológico en la función de la proteína. Se dice que sería útil en el filtro de variantes no sinónimas o indeles que funcionalmente podrían ser importantes, cabe aclarar que nunca probamos este programa en estos puntos y por ello fue que su utilidad en realidad no la explotamos. Este programa es compatible con SIFT y Polyphen2. Aquí los resultados los resume en N: neutral o D: Deletéreo, lógico elegiremos las D.
34. Reliability_index: Este programa vendría siendo un derivado del programa SNPs&GO, se refiere el índice de confiabilidad de una predicción, es decir que tanto es posible confiar en las predicciones realizadas con respecto a una variante, siendo 10 aquellas que totalmente son confiables y 0 aquellas que no son confiables, se basa para esto en comparaciones con otras bases de datos incluyendo 1000 genomas y LR. Para esta no se requiere hacer otra carpeta, simplemente en las variantes que elegiste en otras carpetas, échale un vistazo a esta columna y ve que calidad de predicción te está dando, como dato adicional que podría darte un criterio más de fuerza a la variante que elegiste.
35. SiPhy_29way_logOdds: Este programa es semejante a GERP y a Phylop, predice cosas relacionadas con la conservación a través del tiempo, el problema es que no hay un rango establecido y se me hizo complejo, lo coloco por si logras me lo comentes, no obstante no se le extrañará tanto dado que tenemos otros como es el mismo GERP que nos da información semejante.
36. Variant Effect Scoring Tool (VEST3_rankscore): este programa es útil porque se enfoca a predecir el significado funcional de mutaciones missense, basándose en la probabilidad que tienen estas en afectar la actividad de una proteína. Los puntajes van de 0 a 1, donde 1 se refiere a una mutación funcional con alta confiabilidad. Por tanto para esta elegiremos únicamente aquellas que sean igual o mayor a 0.6, desechando el resto. Cabe mencionar por si se me pasa decirlo, que entodos los rangos que van del 0 al 1 tomaremos a partir de 0.6 en adelante, salvo que la indicación adicional que te proporciono indique lo contrario.
37. BLOSUM62 (BLOcks of Amino Acid SUbstitution Matrix, o matriz de sustitución de bloques de aminoácidos): es una matriz de sustitución utilizada para el alineamiento de secuencias de proteínas. BLOSUM se usa para puntuar alineamientos entre secuencias de proteínas evolutivamente divergentes. BLOSUM 62 es la matriz calculada usando las sustituciones observadas entre proteínas que tienen, como mínimo, el 62% de identidad en la secuencia, y se ha convertido en el estándar de la mayoría de los programas que utilizan este tipo de matrices. De acuerdo a la definición vista, el logaritmo de la ecuación (el resultado de la ecuación, en definitiva) será positivo siempre que el cociente sea mayor de uno. Esto significará que la probabilidad de alineamiento entre los dos aminoácidos en una determinada secuencia se dará con mayor frecuencia que la que podríamos esperar por la mera casualidad. En resumen: esta sustitución es aceptada (en mayor o menor grado, de acuerdo a sus resultados estadísticos) por la evolución. Por el contrario, un logaritmo nulo o negativo implica que las sustituciones se dan al mismo (o menor) ritmo que las esperadas aleatoriamente. Por tanto aquí nos quedaremos con los números negativos, dado que son probablemente donde encontremos la mayor cantidad de mutaciones, desecharemos los positivos.
38. ada_score: este programa predice los efectos en el splicing, considera rangos entre 0 y 1, entre mayor sea el puntaje significa que más probablemente el scSNV afecte el splicing y si es menor significa que no afecta esto. Entonces nosotros tomaremos los valores mayores de 0.6 y desecharemos el resto para analizar estas variantes. rf_score: este es semejante a ada_score y pudieras tenerlos en una misma carpeta, si uno de los dos sobrepasa el 0.6 eliges la variante para analizarla en el siguiente paso, en este caso rf se refiere a una predicción basada en random forests, los rangos son los mismos a los de ada y por tanto tomaras los que digan más de 0.6
39. Consensus Deleteriousness (Condel): como su nombre lo dice este es un Plugin para VEP que une varias herramientas bioinformáticas que ayudan a evaluar el impacto de las SNV no sinónimas en función de la proteína. Por tanto vendría siendo un promedio de las diferentes herramientas computacionales, para no hacer más preámbulo, los resultados de Condel son el resultado del análisis de: SIFT, Polyphen2, MAPP, LogR Pfam E-value, MutationAssessor, FatHMM y Ensembl-variation. Para considerarlos en términos generales clasifica los puntajes en dos: neutral y deletéreo, por lo que elegiremos únicamente aquellas que son deletéreas, lógicamente aplicando todo lo antes comentado.
40. MaxEntScan: MaxEntScan valora la funcionalidad de pequeñas secuencias (6 pb para el sitio 5’donador y 23 pb para el 3’ aceptor) que contienen un único sitio de splicing. Se basa en el Principio de Máxima Entropía y engloba varios modelos probabilísticos de motivos de secuencia como MAXENT (Maximum entropy), MDD (multiple dependence decomposition), MM (first order Markov model) y WMM (weight matrix model). El programa SSPNN identifica todos los posibles sitios de splicing presentes en una secuencia. Para esta última resultaría importante agregarla, no obstante por más que busqué no encontré un parámetro fácil de interpretar que ayudará la selección de los datos, no obstante lo dejo aquí para futuras investigaciones y si encuentras algo lo agregamos, por el momento no lo extrañaremos mucho dado que tenemos el ada y rf_score.

